{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from resnet import ResNet18\n",
    "from network_func import *\n",
    "from optimizer import *\n",
    "from training import *\n",
    "from useful_functions import *\n",
    "from CIFAR10_data_preparation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A的第二大特征值: 0.7360318786212677\n",
      "A的beta: 0.810217360924142\n",
      "A的spectral gap: 0.18978263907585802\n",
      "A的kappa: 2.000000000000005\n",
      "S_A是: 39.898193112709905 \n",
      "\n",
      "1.8413e+00, 2.7000e+01\n"
     ]
    }
   ],
   "source": [
    "n=5\n",
    "I=np.eye(n)\n",
    "one=np.ones(n)\n",
    "R=np.outer(one,one)/n\n",
    "A,C=di_ring(n=n)\n",
    "B=get_B(A=A,u=2*n,n=n)\n",
    "show_row(A)\n",
    "_,__=test_row(A)\n",
    "print(f\"{_:.4e}, {__:.4e}\")\n",
    "h_data,y_data,X_test,y_test=cifar10_prepare_node_5_hard_shuffled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_with_weighted_model_resnet18(model_list, X_test, y_test, weights, criterion, testloader):\n",
    "    # 确保 X_test 和 y_test 在相同的设备上\n",
    "    device = next(model_list[0].parameters()).device\n",
    "\n",
    "    # Step 1: 计算加权模型的参数\n",
    "    avg_model = ResNet18(num_classes=10).to(device)\n",
    "    avg_state_dict = avg_model.state_dict()\n",
    "\n",
    "    # 初始化加权的参数字典\n",
    "    weighted_state_dict = {key: torch.zeros_like(param).to(device) for key, param in avg_state_dict.items()}\n",
    "\n",
    "    # 汇总加权参数\n",
    "    for model, weight in zip(model_list, weights):\n",
    "        state_dict = model.state_dict()\n",
    "        for key in weighted_state_dict.keys():\n",
    "            weighted_state_dict[key] += state_dict[key].to(device) * weight\n",
    "\n",
    "    # 计算总权重\n",
    "    total_weight = sum(weights)\n",
    "    weighted_avg_state_dict = {key: value / total_weight for key, value in weighted_state_dict.items()}\n",
    "\n",
    "    # 将加权参数加载到新模型中\n",
    "    avg_model.load_state_dict(weighted_avg_state_dict)\n",
    "\n",
    "    # 确保测试数据在正确的设备上\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    # Step 2: 评估加权模型的准确性\n",
    "    avg_model.eval()\n",
    "    sum_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = avg_model(X_test)\n",
    "        loss = criterion(outputs, y_test)\n",
    "        sum_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_test.size(0)\n",
    "        correct += predicted.eq(y_test.data).cpu().sum()\n",
    "\n",
    "    val_loss = sum_loss / len(testloader)\n",
    "    val_accu = 100. * correct / total\n",
    "    \n",
    "    return val_loss, val_accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import training\n",
    "importlib.reload(training)\n",
    "from training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer初始化成功!\n",
      "optimizer初始化成功!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument mat in method wrapper_CUDA_addmv_)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Sum_l1, Sum_a1 \u001b[38;5;241m=\u001b[39m \u001b[43msix_GPU_train_PullSum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mResNet18\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed_for_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m49\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_accuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_accuracy_with_weighted_model_resnet18\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GanLuo/PullSum_MNIST/code/神经网络实验/CIFAR10最终实验/training.py:150\u001b[0m, in \u001b[0;36msix_GPU_train_PullSum\u001b[0;34m(n, A, B, model_class, seed_for_model, criterion_class, epochs, lr, X_train_data, y_train_data, X_test_data, y_test_data, compute_accuracy, batch_size, show_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m     h_data_train \u001b[38;5;241m=\u001b[39m batch_h_data\n\u001b[1;32m    149\u001b[0m     y_data_train \u001b[38;5;241m=\u001b[39m batch_y_data\n\u001b[0;32m--> 150\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m    152\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m epoch_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loaders[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;66;03m#标准化\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/GanLuo/PullSum_MNIST/code/神经网络实验/CIFAR10最终实验/optimizer.py:63\u001b[0m, in \u001b[0;36mPullSum_for_try.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprev_v_list contains None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorrection_vector \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrection_vector\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 使用CUDA设备的矩阵运算\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# step1: x = Ax\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_list):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument mat in method wrapper_CUDA_addmv_)"
     ]
    }
   ],
   "source": [
    "Sum_l1, Sum_a1 = six_GPU_train_PullSum(\n",
    "    n=n,\n",
    "    A=A,\n",
    "    B=B,\n",
    "    model_class=ResNet18,\n",
    "    seed_for_model=49,\n",
    "    criterion_class=nn.CrossEntropyLoss,\n",
    "    epochs=50,\n",
    "    lr=3e-3,\n",
    "    batch_size=128,\n",
    "    X_train_data=h_data,\n",
    "    y_train_data=y_data,\n",
    "    X_test_data=X_test,\n",
    "    y_test_data=y_test,\n",
    "    compute_accuracy=compute_accuracy_with_weighted_model_resnet18,\n",
    "    show_graph=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
