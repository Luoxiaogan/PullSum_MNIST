{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Optimizer\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from useful_functions import *\n",
    "from optimizer import *\n",
    "from model import *\n",
    "from MNIST_data_process import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from training import *\n",
    "from mlxtend.data import mnist_data\n",
    "from accuracy_compute import *\n",
    "from data_preparation_easy import *\n",
    "from data_preparation_hard import *\n",
    "from network_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一、 4层神经网络训练MNIST数据集：\n",
    "# 【1】异质性观察\n",
    "# 图1：pulldiag在di_ring(n=5)+三种不同异质性的表现(注：现在只弄了两种异质性，均匀分布和完全异质分布。能不能弄一个稍微混合一点的数据分布？比如在完全异质分布条件下，让1，2号节点数据混合一下。）\n",
    "# 图2：pullsum在di_ring(n=5)+三种不同异质性的表现\n",
    "# 图3：pulldiag和pullsum都在di_ring(n=5)或者di_ring(n=10)+强异质性下的对比表现\n",
    "\n",
    "# 【2】拓扑影响\n",
    "# 图1：在row_and_col_mat(n=10, p=0.5）+强异质性条件下比较pulldiag, pullsum, frsd, frozen \n",
    "# 图2：在row_and_col_mat(n=10, p=0.2）+强异质性条件下比较pulldiag, pullsum, frsd, frozen \n",
    "# 图3：只看pullsum, 在row_and_col_mat(n=10, p=0.5），row_and_col_mat(n=10, p=0.2），di_ring(n=10)，grid_10()上的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图1：pulldiag在di_ring(n=5)+三种不同异质性的表现(注：现在只弄了两种异质性，均匀分布和完全异质分布。能不能弄一个稍微混合一点的数据分布？比如在完全异质分布条件下，让1，2号节点数据混合一下。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A的第二大特征值: 0.7360318786212668\n",
      "A的beta: 0.8102173609241419\n",
      "A的spectral gap: 0.18978263907585813\n",
      "A的kappa: 1.9999999999999976\n",
      "S_A是: 39.89819311270979 \n",
      "\n",
      "1.8413e+00, 2.7000e+01\n"
     ]
    }
   ],
   "source": [
    "#均匀分布数据\n",
    "n=5\n",
    "I=np.eye(n)\n",
    "one=np.ones(n)\n",
    "R=np.outer(one,one)/n\n",
    "A,C=di_ring(n=n)\n",
    "B=get_B(A=A,u=2*n,n=n)\n",
    "show_row(A)\n",
    "_,__=test_row(A)\n",
    "print(f\"{_:.4e}, {__:.4e}\")\n",
    "h_data,y_data,X_test,y_test=prepare_node_5_hard_shuffled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diag_l1, Diag_a1 = train_PullDiag(\n",
    "    n=n,\n",
    "    A=A,\n",
    "    model_class=MNISTClassifier_2layer_2,\n",
    "    seed_for_model=49,\n",
    "    criterion_class=nn.CrossEntropyLoss,\n",
    "    epochs=100,\n",
    "    lr=0.1,\n",
    "    X_train_data=h_data,\n",
    "    y_train_data=y_data,\n",
    "    X_test_data=X_test,\n",
    "    y_test_data=y_test,\n",
    "    compute_accuracy=compute_accuracy_with_average_model,\n",
    "    show_graph=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    # 缩小 lr 的搜索范围，在已找到的最佳值附近搜索\n",
    "    lr = trial.suggest_loguniform('lr',1e-3 , 0.5)\n",
    "\n",
    "    try:\n",
    "        Diag_l1, Diag_a1 = train_PullDiag(\n",
    "            n=n,\n",
    "            A=A,\n",
    "            model_class=MNISTClassifier_2layer_2,\n",
    "            seed_for_model=49,\n",
    "            criterion_class=nn.CrossEntropyLoss,\n",
    "            epochs=25,\n",
    "            lr=lr,\n",
    "            X_train_data=h_data,\n",
    "            y_train_data=y_data,\n",
    "            X_test_data=X_test,\n",
    "            y_test_data=y_test,\n",
    "            compute_accuracy=compute_accuracy_with_average_model,\n",
    "            show_graph=False\n",
    "        )\n",
    "\n",
    "        # 检查 FROZEN_l1 是否包含 inf 或 nan\n",
    "        if np.isnan(Diag_l1).any() or np.isinf(Diag_l1).any():\n",
    "            print(f\"Trial failed due to inf/nan in loss. lr: {lr}\")\n",
    "            return -np.inf  # 返回一个非常低的值\n",
    "\n",
    "        # 返回最终的准确率\n",
    "        return Diag_a1[-1]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed with exception: {e}\")\n",
    "        return -np.inf  # 若发生异常，返回一个非常低的值\n",
    "\n",
    "# 创建一个优化器并使用缩小后的搜索空间进行优化\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(f\"Best parameters: {study.best_params}\")\n",
    "print(f\"Best accuracy: {study.best_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
